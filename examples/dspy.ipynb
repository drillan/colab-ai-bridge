{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## インストール"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q --no-warn-conflicts \"colab-ai-bridge[dspy] @ git+https://github.com/drillan/colab-ai-bridge\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 使い方\n",
        "\n",
        "### 基本的な使い方"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from colab_ai_bridge.dspy import ColabDSPyLM\n",
        "import dspy\n",
        "\n",
        "# モデルの作成とDSPyの設定（セットアップは自動で完了します）\n",
        "lm = ColabDSPyLM()\n",
        "dspy.configure(lm=lm)\n",
        "\n",
        "# Predictorの実行\n",
        "predictor = dspy.Predict(\"question -> answer\")\n",
        "response = predictor(question=\"フランスの首都は？\")\n",
        "print(response.answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### モデルの選択\n",
        "\n",
        "利用可能なモデルを確認："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import ai\n",
        "\n",
        "ai.list_models()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "特定のモデルを使用："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from colab_ai_bridge.dspy import ColabDSPyLM\n",
        "import dspy\n",
        "\n",
        "# Gemini 2.5 Flash Liteを使用\n",
        "lm = ColabDSPyLM(\"google/gemini-2.5-flash-lite\")\n",
        "dspy.configure(lm=lm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 構造化出力\n",
        "\n",
        "DSPy の Signature を使用して型安全な出力を定義："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from colab_ai_bridge.dspy import ColabDSPyLM\n",
        "import dspy\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "\n",
        "class City(BaseModel):\n",
        "    \"\"\"都市情報\"\"\"\n",
        "\n",
        "    name: str = Field(description=\"都市名\")\n",
        "    country: str = Field(description=\"国名\")\n",
        "    population: int = Field(description=\"人口\")\n",
        "\n",
        "\n",
        "class CitySignature(dspy.Signature):\n",
        "    \"\"\"都市について情報を取得する\"\"\"\n",
        "\n",
        "    query: str = dspy.InputField(desc=\"都市に関する質問\")\n",
        "    city_info: City = dspy.OutputField(desc=\"都市情報\")\n",
        "\n",
        "\n",
        "lm = ColabDSPyLM()\n",
        "dspy.configure(lm=lm)\n",
        "\n",
        "predictor = dspy.Predict(CitySignature)\n",
        "response = predictor(query=\"東京について教えて\")\n",
        "city = response.city_info\n",
        "print(f\"{city.name}, {city.country}, 人口: {city.population:,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## サンプル\n",
        "\n",
        "### サンプル 1: リスト型フィールドを持つ構造化出力\n",
        "\n",
        "リスト型フィールドを含むデータモデル"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from colab_ai_bridge.dspy import ColabDSPyLM\n",
        "import dspy\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "\n",
        "class EmailAddress(BaseModel):\n",
        "    \"\"\"メールアドレス情報\"\"\"\n",
        "\n",
        "    email: str = Field(\n",
        "        pattern=r\"^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$\", description=\"メールアドレス\"\n",
        "    )\n",
        "    domain: str = Field(description=\"ドメイン名\")\n",
        "\n",
        "\n",
        "class EmailSignature(dspy.Signature):\n",
        "    \"\"\"メールアドレスから情報を抽出する\"\"\"\n",
        "\n",
        "    email_text: str = dspy.InputField(desc=\"メールアドレスを含むテキスト\")\n",
        "    email_info: EmailAddress = dspy.OutputField(desc=\"抽出されたメールアドレス情報\")\n",
        "\n",
        "\n",
        "lm = ColabDSPyLM()\n",
        "dspy.configure(lm=lm)\n",
        "\n",
        "predictor = dspy.Predict(EmailSignature)\n",
        "response = predictor(email_text=\"example@gmail.comのメールアドレス情報を抽出してください\")\n",
        "email = response.email_info\n",
        "print(f\"メール: {email.email}\")\n",
        "print(f\"ドメイン: {email.domain}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### サンプル 2: ChainOfThought による推論\n",
        "\n",
        "思考の連鎖を使って段階的に推論"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from colab_ai_bridge.dspy import ColabDSPyLM\n",
        "import dspy\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "\n",
        "class Book(BaseModel):\n",
        "    \"\"\"書籍情報\"\"\"\n",
        "\n",
        "    title: str = Field(description=\"タイトル\")\n",
        "    author_name: str = Field(description=\"著者名\")\n",
        "    year: int = Field(description=\"出版年\")\n",
        "    genres: list[str] = Field(description=\"ジャンルのリスト\")\n",
        "\n",
        "\n",
        "class BookSignature(dspy.Signature):\n",
        "    \"\"\"書籍について詳細な情報を取得する\"\"\"\n",
        "\n",
        "    query: str = dspy.InputField(desc=\"書籍に関する質問\")\n",
        "    book_info: Book = dspy.OutputField(desc=\"書籍情報\")\n",
        "\n",
        "\n",
        "lm = ColabDSPyLM()\n",
        "dspy.configure(lm=lm)\n",
        "\n",
        "# ChainOfThoughtを使用して段階的に推論\n",
        "cot = dspy.ChainOfThought(BookSignature)\n",
        "response = cot(query=\"村上春樹の『ノルウェイの森』について教えて\")\n",
        "book = response.book_info\n",
        "print(f\"タイトル: {book.title}\")\n",
        "print(f\"著者: {book.author_name}\")\n",
        "print(f\"出版年: {book.year}\")\n",
        "print(f\"ジャンル: {', '.join(book.genres)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### サンプル 3: カスタムモジュールの作成\n",
        "\n",
        "DSPy Module を使ってカスタムロジックを実装"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from colab_ai_bridge.dspy import ColabDSPyLM\n",
        "import dspy\n",
        "\n",
        "\n",
        "class HistoricalExplainer(dspy.Module):\n",
        "    \"\"\"日本史の専門家として説明するモジュール\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.generate = dspy.ChainOfThought(\"topic -> explanation\")\n",
        "\n",
        "    def forward(self, topic: str) -> dspy.Prediction:\n",
        "        # システムプロンプトを含めたコンテキストを作成\n",
        "        context = (\n",
        "            \"あなたは日本史の専門家です。歴史的な事実を正確に、わかりやすく説明してください。\\n\\n\"\n",
        "            f\"トピック: {topic}\"\n",
        "        )\n",
        "        return self.generate(topic=context)\n",
        "\n",
        "\n",
        "lm = ColabDSPyLM()\n",
        "dspy.configure(lm=lm)\n",
        "\n",
        "explainer = HistoricalExplainer()\n",
        "result = explainer(topic=\"関ヶ原の戦いについて簡潔に説明してください\")\n",
        "print(result.explanation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### サンプル 4: コンテキスト付きプロンプト\n",
        "\n",
        "ユーザーコンテキストを含むパーソナライズされた応答"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from colab_ai_bridge.dspy import ColabDSPyLM\n",
        "import dspy\n",
        "from dataclasses import dataclass\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class UserProfile:\n",
        "    name: str\n",
        "    age: int\n",
        "    interests: list[str]\n",
        "\n",
        "\n",
        "class PersonalizedRecommender(dspy.Module):\n",
        "    \"\"\"ユーザープロフィールに基づいた推薦モジュール\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.recommend = dspy.Predict(\"user_info, request -> recommendations\")\n",
        "\n",
        "    def forward(self, user: UserProfile, request: str) -> dspy.Prediction:\n",
        "        user_info = f\"\"\"ユーザー情報:\n",
        "- 名前: {user.name}\n",
        "- 年齢: {user.age}\n",
        "- 興味: {', '.join(user.interests)}\"\"\"\n",
        "        return self.recommend(user_info=user_info, request=request)\n",
        "\n",
        "\n",
        "lm = ColabDSPyLM()\n",
        "dspy.configure(lm=lm)\n",
        "\n",
        "user = UserProfile(name=\"太郎\", age=25, interests=[\"プログラミング\", \"機械学習\", \"読書\"])\n",
        "recommender = PersonalizedRecommender()\n",
        "result = recommender(user=user, request=\"おすすめの学習リソースを3つ教えてください\")\n",
        "print(result.recommendations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### サンプル 5: 温度パラメータによる出力の違い\n",
        "\n",
        "異なる温度設定での出力比較"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from colab_ai_bridge.dspy import ColabDSPyLM\n",
        "from colab_ai_bridge.core.config import ModelConfig\n",
        "import dspy\n",
        "\n",
        "# 低温度（正確な出力）\n",
        "config_precise = ModelConfig(temperature=0.3)\n",
        "lm_precise = ColabDSPyLM(config=config_precise)\n",
        "\n",
        "# 高温度（創造的な出力）\n",
        "config_creative = ModelConfig(temperature=1.0)\n",
        "lm_creative = ColabDSPyLM(config=config_creative)\n",
        "\n",
        "predictor = dspy.Predict(\"question -> answer\")\n",
        "prompt = \"AIについて一文で説明してください\"\n",
        "\n",
        "print(\"【正確な出力 (temperature=0.3)】\")\n",
        "dspy.configure(lm=lm_precise)\n",
        "result1 = predictor(question=prompt)\n",
        "print(result1.answer)\n",
        "print()\n",
        "\n",
        "print(\"【創造的な出力 (temperature=1.0)】\")\n",
        "dspy.configure(lm=lm_creative)\n",
        "result2 = predictor(question=prompt)\n",
        "print(result2.answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### サンプル 6: 最適化とキャッシング\n",
        "\n",
        "DSPy のキャッシュ機能を活用"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from colab_ai_bridge.dspy import ColabDSPyLM\n",
        "import dspy\n",
        "import time\n",
        "\n",
        "# キャッシュ有効（デフォルト）\n",
        "lm_cached = ColabDSPyLM(cache=True)\n",
        "dspy.configure(lm=lm_cached)\n",
        "\n",
        "predictor = dspy.Predict(\"question -> answer\")\n",
        "question = \"日本の四季について説明してください\"\n",
        "\n",
        "print(\"【1回目（キャッシュなし）】\")\n",
        "start = time.time()\n",
        "result1 = predictor(question=question)\n",
        "time1 = time.time() - start\n",
        "print(f\"実行時間: {time1:.2f}秒\")\n",
        "print(result1.answer[:100] + \"...\")\n",
        "print()\n",
        "\n",
        "print(\"【2回目（キャッシュ使用）】\")\n",
        "start = time.time()\n",
        "result2 = predictor(question=question)\n",
        "time2 = time.time() - start\n",
        "print(f\"実行時間: {time2:.2f}秒\")\n",
        "print(result2.answer[:100] + \"...\")\n",
        "print()\n",
        "print(f\"速度向上: {time1/time2:.2f}x\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
